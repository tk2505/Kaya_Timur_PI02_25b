1. Вариант 6:
Задание 6: CNN для классификации изображений (Fashion-MNIST)
Задача: создать сверточную нейронную сеть (CNN) для классификации элементов
одежды из Fashion-MNIST.
Требования:
Архитектура: Conv2D(32) → MaxPooling → Conv2D(64) → MaxPooling →
Dense(128) → Dense(10)
Использовать ReLU активацию для скрытых слоёв
Data augmentation (случайные повороты, сдвиги)
Dropout для регуляризации
Код-заготовка (Python):
import tensorflow as tf
from tensorflow import keras
import numpy as np
class FashionMNISTCNN:
 def __init__(self):
 # TODO: Создать модель с conv2d и maxpooling слоями
 # Архитектура:
 # - Conv2D(32, kernel_size=3, padding='same')
 # - MaxPooling2D(2)
 # - Conv2D(64, kernel_size=3, padding='same')
 # - MaxPooling2D(2)
 # - Flatten()
 # - Dense(128, activation='relu')
 # - Dropout(0.5)
 # - Dense(10, activation='softmax')
 self.model = None

 def load_and_preprocess_data(self):
 # TODO: Загрузить Fashion-MNIST
 # Нормализовать пиксели на диапазон [0, 1]
 # Добавить размерность канала: (28, 28) -> (28, 28, 1)
 pass

 def create_data_augmentation(self):
 # TODO: Создать pipeline data augmentation
 # - RandomRotation(0.1)
 # - RandomZoom(0.1)
 # - RandomTranslation(0.1, 0.1)
 pass
43

 def compile_model(self):
 # TODO: Скомпилировать модель
 # Optimizer: Adam
 # Loss: categorical_crossentropy
 # Metrics: accuracy
 pass

 def train(self, X_train, y_train, epochs=10, batch_size=32):
 # TODO: Обучить модель с augmentation
 # Использовать validation_split=0.2
 pass

 def evaluate(self, X_test, y_test):
 # TODO: Оценить точность на тестовой выборке
 pass
# Что нужно дополнить:
# 1. Создание слоёв Conv2D и MaxPooling2D
# 2. Pipeline аугментации данных
# 3. Компиляцию и обучение модели
# 4. Визуализацию predictions и ошибок
# 5. Анализ характеристик фильтров (filters visualization)

2. Алгоритм работы НС по блокам:
Блок 1. Подготовка и загрузка данных
Загружается CSV‑файл fashion-mnist_*.csv, где первая колонка — метка класса (0–9), остальные 784 значения — яркости пикселей 28×28.
Массив признаков преобразуется в тип float32, нормализуется делением на 255, чтобы значения были в диапазоне, и меняет форму с (N, 784) на (N, 28, 28, 1) для подачи в сверточные слои.​
Набор данных делится на обучающую, валидационную и тестовую выборки (например, 80% / 20%, затем из обучающей ещё выделяется часть под валидацию) с сохранением соотношения классов.

Блок 2. Аугментация изображений
Создается генератор аугментации, который к изображению добавляет небольшие случайные преобразования: поворот на малый угол, масштабирование (zoom), горизонтальные и вертикальные сдвиги.
Эти операции увеличивают разнообразие обучающих примеров, не изменяя сам класс объекта, что помогает сети лучше обобщать и меньше переобучаться.
На каждом шаге обучения в сеть подаются не исходные картинки, а их случайно искажённые версии, с теми же метками.

Блок 3. Архитектура сверточной сети
На вход подаются изображения размера 28×28×1 (один канал, градации серого).
Первый блок: сверточный слой с 32 фильтрами 3×3 и активацией ReLU вычисляет локальные признаки (контуры, края и простые текстуры), затем слой подвыборки MaxPooling 2×2 уменьшает размер карты признаков, сохраняя самые ярко выраженные отклики.
Второй блок: ещё один сверточный слой с 64 фильтрами 3×3 и последующим MaxPooling 2×2 извлекает более сложные и абстрактные признаки (части одежды, формы областей).

Блок 4. Полносвязная часть и классификация
Выход последнего слоя подвыборки разворачивается в одномерный вектор с помощью операции Flatten, что превращает набор карт признаков в список чисел.
Полносвязный слой из 128 нейронов с ReLU комбинирует найденные признаки и формирует более высокоуровневое представление объекта (например, тип одежды).
Слой Dropout с вероятностью 0.5 случайно «выключает» половину нейронов на каждом шаге обучения, уменьшая переобучение и заставляя сеть учиться более устойчивым комбинациям признаков.
Финальный полносвязный слой с 10 нейронами и активацией softmax выдаёт распределение вероятностей по 10 классам одежды; индекс максимального выхода принимается как предсказанный класс.

Блок 5. Обучение и контроль качества
Модель компилируется с функцией потерь sparse_categorical_crossentropy, оптимизатором Adam и метрикой accuracy; это задаёт правило, по которому сеть корректирует веса.
В цикле по эпохам генератор аугментации формирует батчи и подаёт их в сеть, которая распространяет сигнал вперёд (forward pass), считает ошибку, а затем с помощью обратного распространения и Adam обновляет веса фильтров и полносвязных слоёв.
После каждой эпохи считается качество на валидационном наборе, а история обучения (точность и ошибка на обучении и валидации) сохраняется в объекте history, по которому строятся графики acc/loss для анализа динамики обучения.

Блок 6. Тестирование, предсказания и ошибки
После завершения обучения модель замораживает веса и оценивается на отложенной тестовой выборке, которую она не видела во время тренировки — это даёт реальную оценку обобщающей способности.
Для анализа ошибок сеть получает предсказания на тесте, сравниваются предсказанные классы с истинными, выбираются примеры, где модель ошиблась, и изображения этих примеров визуализируются с подписями «истинный/предсказанный класс».
Такой просмотр показывает, с какими типами объектов сеть справляется хуже (например, путает «shirt» и «T‑shirt» или «coat» и «pullover») и помогает понять, достаточно ли разнообразен и чист набор данных.

Блок 7. Анализ характеристик фильтров
Из первого сверточного слоя извлекаются обученные фильтры (веса размером 3×3), нормализуются в диапазон и отображаются как маленькие изображения; по ним видно, какие «паттерны» (горизонтальные/вертикальные линии, наклонные края, простые текстуры) сеть научилась выделять.​
Для выбранного изображения тестового набора считается отклик первого сверточного слоя (feature maps): для каждого фильтра показывается карта активаций, по которой видно, какие области исходного изображения этот фильтр «зажёг».
Совместный анализ самих фильтров и их карт активаций показывает, какие формы и детали одежды важны для классификации в данной сети и насколько осмысленны выученные признаки.

3. Ответ на контрольный вопрос
Вопрос: Почему алгоритмы во внешней памяти измеряют сложность в операциях I/O, а
не в сравнениях?
Ответ: алгоритмы во внешней памяти измеряют сложность в операциях ввода‑вывода, потому что именно чтение и запись на диск являются самым медленным этапом работы, а не сами вычисления и сравнения. Данные не помещаются целиком в оперативную память, поэтому обрабатываются блоками; каждая загрузка или запись блока — дорогостоящая операция, и суммарное число таких операций почти полностью определяет время работы алгоритма. Сравнения внутри уже загруженного блока выполняются очень быстро по сравнению с диском, поэтому их вклад во время можно считать почти бесплатным, и два алгоритма с одинаковым числом сравнений, но разным числом операций I/O на практике будут работать заметно по‑разному.
